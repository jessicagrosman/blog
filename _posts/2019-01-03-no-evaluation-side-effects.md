---
title: "No Evaulation? Possible side effects include"
categories: reflections
---

### How do you measure training effectiveness?
 
Many projects are evaluated by two things: 


1. On Schedule? 
2. On Budget?

These two elements completely ignore the point of training: _people’s performance_
 
Many of us can agree that not measuring the results of training is bad, even if the best way to calculate ROI for training is not always intuitive or possible. There has to be other ways to rigorously measure training programs.
 
It takes serious thinking to set training goals and evaluate their effectiveness. Let's be honest, with training evaluation, we’re trying to figure out what good training at our organization looks like, but we’re also trying to make training a much-loved and respected department within the organization. This quest leads Cathy Moore to assert that all good training goals have to be attached to business goals. For example, a decrease in calls to technical support after an upgrade or a reduced number of health and safety incidents. If these business goals are met, the training and all the other work is considered a success.
 
But back to what happens if we don't evaluate training. There can be unintended side-effects
 
1.	Manager feedback replaces learner feedback
2.	A few voices stand in for all 
3.	Meaningless survey questions are appended to programs
4.	Popular notions about training cloud real-evidence based results
 
###This 5th side effect hit me recently:
5. Evaluation gets stuck to a specific moment, instead of measuring change over time.

When you don't measure the effectiveness of training, an impromptu assessment is deeply rooted in our perception, in the present moment. This perspective washes away much of the larger context. We can't see the changes as easily, unless they are apparent today. 
 
Allow me to make a couple analogies.

> Evaluating a training program only from how it looks today embodies a similar reflex to when we see a friend's lovely photo on social media and can’t stop ourselves from thinking for a moment that their whole life it is that perfect (even if we really know better). 

Or if we visit a garden in August with all the blooms and forget the garden also lives through other seasons.
 
Similarly, if we have no serious way to measure training results, then today’s perception of the training will lead to a moment in time standing in for the larger impact of the training. 

The squeaky wheel, complaining at our desk right now might overpower other results or feedback. 

A comparison to a fancier course from a more established training team might obscure the efficiency of our own humbler endeavours. 

We are using how we feel, what issues preoccupy us today to stand in for learner experience and performance.
 
Supervisors might come to a conclusion about the effectiveness of the training program at the wrong moment: before the learners have had a chance to practice or apply the training in real situations.

**Whole projects haven been scrapped in similar scenario; I am sure.** 

And back to how evaluation integrates us into the organization"

**If we don't track results, one day it becomes harder to argue for a changed methodology, or to sit in on the new product management meetings, or to ask for a conference ticket or a new tool, perhaps even good budget.**
